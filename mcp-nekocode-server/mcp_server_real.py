#!/usr/bin/env python3
"""
ğŸ± NekoCode MCP Server - å®Ÿéš›ã®MCPå®Ÿè£…ç‰ˆ

å®Ÿéš›ã®MCPãƒ—ãƒ­ãƒˆã‚³ãƒ«ï¼ˆstdio + JSON-RPCï¼‰ã§å®Ÿè£…
"""

import asyncio
import json
import sys
import subprocess
import os
from typing import Dict, List, Any, Optional
import logging

# ãƒ­ã‚°è¨­å®š (stderrã«å‡ºåŠ›ã€stdioã¨æ··åŒã—ãªã„ã‚ˆã†ã«)
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    stream=sys.stderr
)
logger = logging.getLogger(__name__)


class NekoCodeMCPServer:
    """å®Ÿéš›ã®MCPãƒ—ãƒ­ãƒˆã‚³ãƒ«å®Ÿè£…"""
    
    def __init__(self):
        self.nekocode_path = self._find_nekocode_binary()
        self.sessions = {}
        self.tools = self._define_tools()
        self.config = self._load_config()
    
    def _find_nekocode_binary(self) -> str:
        """nekocode-rust ãƒã‚¤ãƒŠãƒªã®å ´æ‰€ã‚’ç‰¹å®š"""
        # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ã‚’å„ªå…ˆ
        env_path = os.environ.get('NEKOCODE_BINARY_PATH')
        if env_path and os.path.exists(env_path):
            return os.path.abspath(env_path)
        
        possible_paths = [
            # ğŸ¦€ NEW: Rustç‰ˆã®ãƒã‚¤ãƒŠãƒªãƒ‘ã‚¹ã‚’å„ªå…ˆ
            "./target/release/nekocode-rust",
            "../target/release/nekocode-rust",
            "./target/debug/nekocode-rust",
            "../target/debug/nekocode-rust",
            # ğŸš€ GitHub Actions / CIç”¨ releases/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            "./releases/nekocode-rust",
            "../releases/nekocode-rust",
            # Legacy C++ paths  
            "./bin/nekocode_ai",
            "../bin/nekocode_ai",
            "./build/nekocode_ai",
            "../build/nekocode_ai", 
            "/usr/local/bin/nekocode_ai",
            "nekocode_ai",
            "nekocode-rust"
        ]
        
        for path in possible_paths:
            if os.path.exists(path):
                return os.path.abspath(path)
        
        # PATHã‹ã‚‰æ¤œç´¢ï¼ˆRustç‰ˆã‚’å„ªå…ˆï¼‰
        import shutil
        rust_binary = shutil.which("nekocode-rust")
        if rust_binary:
            return rust_binary
        
        legacy_binary = shutil.which("nekocode_ai")
        if legacy_binary:
            return legacy_binary
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼ˆRustç‰ˆã‚’å„ªå…ˆï¼‰
        return "./target/release/nekocode-rust"
    
    def _load_config(self) -> Dict:
        """nekocode_config.json ã‚’èª­ã¿è¾¼ã¿ï¼ˆã‚ã‚Œã°ï¼‰"""
        try:
            # nekocode_ai ã¨åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
            config_path = os.path.join(
                os.path.dirname(self.nekocode_path),
                "nekocode_config.json"
            )
            
            if os.path.exists(config_path):
                with open(config_path, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    logger.info(f"ğŸ“‹ Config loaded from: {config_path}")
                    logger.info(f"   History limit: {config.get('memory', {}).get('edit_history', {}).get('max_size_mb', 10)} MB")
                    return config
            else:
                logger.info("ğŸ“‹ Using default config (no config file found)")
                return {
                    "memory": {
                        "edit_history": {"max_size_mb": 10, "min_files_keep": 10},
                        "edit_previews": {"max_size_mb": 5}
                    },
                    "token_limits": {
                        "ast_dump_max": 8000,
                        "summary_threshold": 1000,
                        "allow_force_output": True
                    }
                }
        except Exception as e:
            logger.warning(f"âš ï¸ Config load error: {e}, using defaults")
            return {
                "memory": {
                    "edit_history": {"max_size_mb": 10, "min_files_keep": 10},
                    "edit_previews": {"max_size_mb": 5}
                },
                "token_limits": {
                    "ast_dump_max": 8000,
                    "summary_threshold": 1000,
                    "allow_force_output": True
                }
            }
    
    def _define_tools(self) -> List[Dict]:
        """åˆ©ç”¨å¯èƒ½ãªãƒ„ãƒ¼ãƒ«å®šç¾©"""
        return [
            {
                "name": "analyze",
                "description": "ğŸš€ é«˜é€Ÿãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè§£æ",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "path": {"type": "string", "description": "è§£æå¯¾è±¡ãƒ‘ã‚¹"},
                        "language": {"type": "string", "description": "è¨€èªæŒ‡å®š", "default": "auto"},
                        "stats_only": {"type": "boolean", "description": "çµ±è¨ˆã®ã¿", "default": False}
                    },
                    "required": ["path"]
                }
            },
            {
                "name": "session_create",
                "description": "ğŸ® å¯¾è©±å¼ã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆ",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "path": {"type": "string", "description": "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‘ã‚¹"}
                    },
                    "required": ["path"]
                }
            },
            {
                "name": "session_stats",
                "description": "ğŸ“Š ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ±è¨ˆæƒ…å ±",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "session_id": {"type": "string", "description": "ã‚»ãƒƒã‚·ãƒ§ãƒ³ID"}
                    },
                    "required": ["session_id"]
                }
            },
            {
                "name": "session_update",
                "description": "âš¡ ã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ã‚¿ãƒ«è§£æ (è¶…é«˜é€Ÿæ›´æ–°)",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "session_id": {"type": "string", "description": "ã‚»ãƒƒã‚·ãƒ§ãƒ³ID"},
                        "verbose": {"type": "boolean", "description": "è©³ç´°JSONå‡ºåŠ›", "default": False},
                        "dry_run": {"type": "boolean", "description": "å¤‰æ›´ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ã¿", "default": False}
                    },
                    "required": ["session_id"]
                }
            },
            {
                "name": "include_cycles",
                "description": "ğŸ” C++å¾ªç’°ä¾å­˜æ¤œå‡º",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "session_id": {"type": "string", "description": "ã‚»ãƒƒã‚·ãƒ§ãƒ³ID"}
                    },
                    "required": ["session_id"]
                }
            },
            {
                "name": "include_graph",
                "description": "ğŸŒ C++ä¾å­˜é–¢ä¿‚ã‚°ãƒ©ãƒ•",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "session_id": {"type": "string", "description": "ã‚»ãƒƒã‚·ãƒ§ãƒ³ID"}
                    },
                    "required": ["session_id"]
                }
            },
            {
                "name": "list_languages",
                "description": "ğŸŒ ã‚µãƒãƒ¼ãƒˆè¨€èªä¸€è¦§",
                "inputSchema": {"type": "object", "properties": {}}
            },
            {
                "name": "replace_preview",
                "description": "ğŸ“ ç½®æ›ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸è¦ãƒ»ç›´æ¥å®Ÿè¡Œï¼‰",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "file_path": {"type": "string", "description": "ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹"},
                        "pattern": {"type": "string", "description": "æ¤œç´¢ãƒ‘ã‚¿ãƒ¼ãƒ³"},
                        "replacement": {"type": "string", "description": "ç½®æ›æ–‡å­—åˆ—"}
                    },
                    "required": ["file_path", "pattern", "replacement"]
                }
            },
            {
                "name": "replace_confirm",
                "description": "âœ… ç½®æ›å®Ÿè¡Œï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸è¦ãƒ»ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼IDæŒ‡å®šï¼‰",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "preview_id": {"type": "string", "description": "ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ID"}
                    },
                    "required": ["preview_id"]
                }
            },
            {
                "name": "insert_preview",
                "description": "ğŸ“ æŒ¿å…¥ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸è¦ãƒ»start/end/è¡Œç•ªå·ï¼‰",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "file_path": {"type": "string", "description": "ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹"},
                        "position": {"type": "string", "description": "æŒ¿å…¥ä½ç½®ï¼ˆstart/end/è¡Œç•ªå·ï¼‰"},
                        "content": {"type": "string", "description": "æŒ¿å…¥å†…å®¹"}
                    },
                    "required": ["file_path", "position", "content"]
                }
            },
            {
                "name": "insert_confirm",
                "description": "âœ… æŒ¿å…¥å®Ÿè¡Œï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸è¦ãƒ»ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼IDæŒ‡å®šï¼‰",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "preview_id": {"type": "string", "description": "ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ID"}
                    },
                    "required": ["preview_id"]
                }
            },
            {
                "name": "movelines_preview",
                "description": "ğŸ”„ è¡Œç§»å‹•ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸è¦ãƒ»ãƒ•ã‚¡ã‚¤ãƒ«é–“ç§»å‹•ï¼‰",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "srcfile": {"type": "string", "description": "ã‚½ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹"},
                        "start_line": {"type": "integer", "description": "é–‹å§‹è¡Œç•ªå·ï¼ˆ1ãƒ™ãƒ¼ã‚¹ï¼‰"},
                        "line_count": {"type": "integer", "description": "ç§»å‹•è¡Œæ•°"},
                        "dstfile": {"type": "string", "description": "å®›å…ˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹"},
                        "insert_line": {"type": "integer", "description": "æŒ¿å…¥è¡Œç•ªå·ï¼ˆ1ãƒ™ãƒ¼ã‚¹ï¼‰"}
                    },
                    "required": ["srcfile", "start_line", "line_count", "dstfile", "insert_line"]
                }
            },
            {
                "name": "movelines_confirm",
                "description": "âœ… è¡Œç§»å‹•å®Ÿè¡Œï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸è¦ãƒ»ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼IDæŒ‡å®šï¼‰",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "preview_id": {"type": "string", "description": "ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ID"}
                    },
                    "required": ["preview_id"]
                }
            },
            {
                "name": "edit_history",
                "description": "ğŸ“‹ ç·¨é›†å±¥æ­´è¡¨ç¤ºï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸è¦ãƒ»æœ€æ–°20ä»¶ï¼‰",
                "inputSchema": {
                    "type": "object",
                    "properties": {}
                }
            },
            {
                "name": "edit_show",
                "description": "ğŸ” ç·¨é›†è©³ç´°è¡¨ç¤ºï¼ˆIDæŒ‡å®šï¼‰",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "session_id": {"type": "string", "description": "ã‚»ãƒƒã‚·ãƒ§ãƒ³ID"},
                        "edit_id": {"type": "string", "description": "ç·¨é›†ID"}
                    },
                    "required": ["session_id", "edit_id"]
                }
            },
            {
                "name": "ast_stats",
                "description": "ğŸŒ³ ASTçµ±è¨ˆæƒ…å ±ï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³ï¼‰",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "session_id": {"type": "string", "description": "ã‚»ãƒƒã‚·ãƒ§ãƒ³ID"}
                    },
                    "required": ["session_id"]
                }
            },
            {
                "name": "ast_query",
                "description": "ğŸ” ASTæ§‹é€ ã‚¯ã‚¨ãƒªï¼ˆãƒ‘ã‚¹æŒ‡å®šï¼‰",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "session_id": {"type": "string", "description": "ã‚»ãƒƒã‚·ãƒ§ãƒ³ID"},
                        "path": {"type": "string", "description": "ã‚¯ã‚¨ãƒªãƒ‘ã‚¹ï¼ˆä¾‹: MyClass::myMethodï¼‰"}
                    },
                    "required": ["session_id", "path"]
                }
            },
            {
                "name": "scope_analysis",
                "description": "ğŸ¯ ã‚¹ã‚³ãƒ¼ãƒ—è§£æï¼ˆè¡Œç•ªå·æŒ‡å®šï¼‰",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "session_id": {"type": "string", "description": "ã‚»ãƒƒã‚·ãƒ§ãƒ³ID"},
                        "line": {"type": "integer", "description": "è§£æå¯¾è±¡è¡Œç•ªå·"}
                    },
                    "required": ["session_id", "line"]
                }
            },
            {
                "name": "ast_dump",
                "description": "ğŸ“Š ASTæ§‹é€ ãƒ€ãƒ³ãƒ—ï¼ˆå½¢å¼æŒ‡å®šãƒ»ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™å¯¾å¿œï¼‰",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "session_id": {"type": "string", "description": "ã‚»ãƒƒã‚·ãƒ§ãƒ³ID"},
                        "format": {"type": "string", "description": "å‡ºåŠ›å½¢å¼ï¼ˆtree/json/flatï¼‰", "default": "tree"},
                        "force": {"type": "boolean", "description": "å¼·åˆ¶å…¨å‡ºåŠ›ï¼ˆãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™ç„¡è¦–ï¼‰", "default": False},
                        "limit": {"type": "integer", "description": "å‡ºåŠ›è¡Œæ•°åˆ¶é™ï¼ˆçœç•¥å¯ï¼‰"}
                    },
                    "required": ["session_id"]
                }
            },
            {
                "name": "moveclass_preview",
                "description": "ğŸ”„ ã‚¯ãƒ©ã‚¹ç§»å‹•ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³ï¼‰",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "session_id": {"type": "string", "description": "ã‚»ãƒƒã‚·ãƒ§ãƒ³ID"},
                        "symbol_id": {"type": "string", "description": "ç§»å‹•å¯¾è±¡ã‚·ãƒ³ãƒœãƒ«ID"},
                        "target": {"type": "string", "description": "ç§»å‹•å…ˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹"}
                    },
                    "required": ["session_id", "symbol_id", "target"]
                }
            },
            {
                "name": "moveclass_confirm",
                "description": "âœ… ã‚¯ãƒ©ã‚¹ç§»å‹•å®Ÿè¡Œï¼ˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼IDæŒ‡å®šï¼‰",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "preview_id": {"type": "string", "description": "ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ID"}
                    },
                    "required": ["preview_id"]
                }
            },
            {
                "name": "memory_save",
                "description": "ğŸ’¾ ãƒ¡ãƒ¢ãƒªä¿å­˜ï¼ˆã‚¿ã‚¤ãƒ—ãƒ»åå‰ãƒ»å†…å®¹æŒ‡å®šï¼‰",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "memory_type": {"type": "string", "description": "ãƒ¡ãƒ¢ãƒªã‚¿ã‚¤ãƒ—ï¼ˆauto/memo/api/cacheï¼‰"},
                        "name": {"type": "string", "description": "ãƒ¡ãƒ¢ãƒªå"},
                        "content": {"type": "string", "description": "ä¿å­˜å†…å®¹"}
                    },
                    "required": ["memory_type", "name", "content"]
                }
            },
            {
                "name": "memory_load",
                "description": "ğŸ“‚ ãƒ¡ãƒ¢ãƒªèª­ã¿è¾¼ã¿ï¼ˆã‚¿ã‚¤ãƒ—ãƒ»åå‰æŒ‡å®šï¼‰",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "memory_type": {"type": "string", "description": "ãƒ¡ãƒ¢ãƒªã‚¿ã‚¤ãƒ—"},
                        "name": {"type": "string", "description": "ãƒ¡ãƒ¢ãƒªå"}
                    },
                    "required": ["memory_type", "name"]
                }
            },
            {
                "name": "memory_list",
                "description": "ğŸ“‹ ãƒ¡ãƒ¢ãƒªä¸€è¦§ï¼ˆã‚¿ã‚¤ãƒ—ãƒ•ã‚£ãƒ«ã‚¿å¯èƒ½ï¼‰",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "memory_type": {"type": "string", "description": "ãƒ•ã‚£ãƒ«ã‚¿ç”¨ãƒ¡ãƒ¢ãƒªã‚¿ã‚¤ãƒ—ï¼ˆçœç•¥å¯ï¼‰"}
                    }
                }
            },
            {
                "name": "memory_timeline",
                "description": "ğŸ“… ãƒ¡ãƒ¢ãƒªã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ï¼ˆæ—¥æ•°æŒ‡å®šï¼‰",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "memory_type": {"type": "string", "description": "ãƒ•ã‚£ãƒ«ã‚¿ç”¨ãƒ¡ãƒ¢ãƒªã‚¿ã‚¤ãƒ—ï¼ˆçœç•¥å¯ï¼‰"},
                        "days": {"type": "integer", "description": "è¡¨ç¤ºæ—¥æ•°", "default": 7}
                    }
                }
            },
            {
                "name": "config_show",
                "description": "âš™ï¸ è¨­å®šè¡¨ç¤º",
                "inputSchema": {
                    "type": "object",
                    "properties": {}
                }
            },
            {
                "name": "config_set",
                "description": "âš™ï¸ è¨­å®šå¤‰æ›´ï¼ˆã‚­ãƒ¼ãƒ»å€¤æŒ‡å®šï¼‰",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "key": {"type": "string", "description": "è¨­å®šã‚­ãƒ¼"},
                        "value": {"type": "string", "description": "è¨­å®šå€¤"}
                    },
                    "required": ["key", "value"]
                }
            },
            {
                "name": "watch_start",
                "description": "ğŸ” ãƒ•ã‚¡ã‚¤ãƒ«ç›£è¦–é–‹å§‹ï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è§£æï¼‰",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "session_id": {"type": "string", "description": "ç›£è¦–å¯¾è±¡ã‚»ãƒƒã‚·ãƒ§ãƒ³ID"}
                    },
                    "required": ["session_id"]
                }
            },
            {
                "name": "watch_status",
                "description": "ğŸ“Š ãƒ•ã‚¡ã‚¤ãƒ«ç›£è¦–çŠ¶æ…‹ç¢ºèª",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "session_id": {"type": "string", "description": "ã‚»ãƒƒã‚·ãƒ§ãƒ³IDï¼ˆçœç•¥æ™‚ã¯å…¨ã‚»ãƒƒã‚·ãƒ§ãƒ³ï¼‰"}
                    }
                }
            },
            {
                "name": "watch_stop",
                "description": "ğŸ›‘ ãƒ•ã‚¡ã‚¤ãƒ«ç›£è¦–åœæ­¢",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "session_id": {"type": "string", "description": "åœæ­¢å¯¾è±¡ã‚»ãƒƒã‚·ãƒ§ãƒ³ID"}
                    },
                    "required": ["session_id"]
                }
            },
            {
                "name": "watch_stop_all",
                "description": "ğŸ›‘ å…¨ãƒ•ã‚¡ã‚¤ãƒ«ç›£è¦–åœæ­¢",
                "inputSchema": {
                    "type": "object",
                    "properties": {}
                }
            },
            {
                "name": "watch_config",
                "description": "âš™ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ç›£è¦–è¨­å®šè¡¨ç¤º",
                "inputSchema": {
                    "type": "object",
                    "properties": {}
                }
            }
        ]
    
    def _extract_summary(self, result: Dict) -> str:
        """è§£æçµæœã‹ã‚‰çµ±è¨ˆã‚µãƒãƒªãƒ¼ã‚’æŠ½å‡º"""
        try:
            if "error" in result:
                return json.dumps(result, indent=2, ensure_ascii=False)
            
            summary = []
            summary.append("ğŸ“Š **è§£æçµæœã‚µãƒãƒªãƒ¼**\n")
            
            # åŸºæœ¬æƒ…å ±
            if "directory_path" in result:
                summary.append(f"ğŸ“ ãƒ‘ã‚¹: {result['directory_path']}")
            
            # ãƒ•ã‚¡ã‚¤ãƒ«çµ±è¨ˆ
            if "files" in result:
                files = result["files"]
                total_files = len(files)
                summary.append(f"ğŸ“„ ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {total_files}")
                
                # è¨€èªåˆ¥çµ±è¨ˆ
                lang_counts = {}
                total_functions = 0
                total_classes = 0
                total_lines = 0
                total_code_lines = 0
                
                for file in files:
                    lang = file.get("language", "unknown")
                    lang_counts[lang] = lang_counts.get(lang, 0) + 1
                    
                    if "functions" in file:
                        total_functions += len(file["functions"])
                    if "classes" in file:
                        total_classes += len(file["classes"])
                    if "file_info" in file:
                        info = file["file_info"]
                        total_lines += info.get("total_lines", 0)
                        total_code_lines += info.get("code_lines", 0)
                
                summary.append(f"\nğŸ“ˆ **çµ±è¨ˆæƒ…å ±:**")
                summary.append(f"  â€¢ ç·è¡Œæ•°: {total_lines:,}")
                summary.append(f"  â€¢ ã‚³ãƒ¼ãƒ‰è¡Œæ•°: {total_code_lines:,}")
                summary.append(f"  â€¢ é–¢æ•°æ•°: {total_functions:,}")
                summary.append(f"  â€¢ ã‚¯ãƒ©ã‚¹æ•°: {total_classes:,}")
                
                if lang_counts:
                    summary.append(f"\nğŸ—‚ï¸ **è¨€èªåˆ¥:**")
                    for lang, count in sorted(lang_counts.items()):
                        summary.append(f"  â€¢ {lang}: {count} files")
            
            # å®Ÿè¡Œæ™‚é–“æƒ…å ±ï¼ˆã‚‚ã—ã‚ã‚Œã°ï¼‰
            if "output" in result and "Total directory analysis took:" in result.get("output", ""):
                # outputã‹ã‚‰å®Ÿè¡Œæ™‚é–“ã‚’æŠ½å‡º
                output_lines = result["output"].split("\n")
                for line in output_lines:
                    if "Total directory analysis took:" in line:
                        summary.append(f"\nâ±ï¸ {line.strip()}")
                        break
            
            return "\n".join(summary)
            
        except Exception as e:
            logger.error(f"ã‚µãƒãƒªãƒ¼æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å°‘ãªãã¨ã‚‚åŸºæœ¬æƒ…å ±ã‚’è¿”ã™
            return f"âš ï¸ ã‚µãƒãƒªãƒ¼ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}\n\nå…ƒãƒ‡ãƒ¼ã‚¿ã®ã‚­ãƒ¼: {list(result.keys())}"
    
    async def _run_nekocode(self, args: List[str]) -> Dict:
        """NekoCodeå®Ÿè¡Œ"""
        try:
            cmd = [self.nekocode_path] + args
            logger.info(f"Executing: {' '.join(cmd)}")
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
            
            # --helpãªã©ã¯0ä»¥å¤–ã®return codeã§ã‚‚æ­£å¸¸
            if result.returncode != 0 and "--help" not in args:
                return {"error": f"NekoCodeå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {result.stderr}"}
            
            # stderrã«å‡ºåŠ›ã•ã‚Œã‚‹å ´åˆã‚‚ã‚ã‚‹ï¼ˆhelpãªã©ï¼‰
            output = result.stdout if result.stdout.strip() else result.stderr
            
            # Rustç‰ˆã¯ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹æƒ…å ±ã‚’JSONå‰ã«å‡ºåŠ›ã™ã‚‹ã®ã§ã€JSONéƒ¨åˆ†ã ã‘ã‚’æŠ½å‡º
            lines = output.split('\n')
            json_start = -1
            for i, line in enumerate(lines):
                if line.strip().startswith('{'):
                    json_start = i
                    break
            
            if json_start >= 0:
                # JSONéƒ¨åˆ†ã ã‘ã‚’å–ã‚Šå‡ºã—ã¦è§£æ
                json_text = '\n'.join(lines[json_start:])
                try:
                    return json.loads(json_text)
                except json.JSONDecodeError:
                    # JSONãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ãŸå ´åˆã¯å…ƒã®å‡ºåŠ›ã‚’è¿”ã™
                    return {"output": output, "raw": True}
            else:
                # JSONé–‹å§‹ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€å…¨ä½“ã‚’JSONã¨ã—ã¦è§£æã‚’è©¦ã¿ã‚‹
                try:
                    return json.loads(output)
                except json.JSONDecodeError:
                    return {"output": output, "raw": True}
                
        except subprocess.TimeoutExpired:
            return {"error": "å®Ÿè¡ŒãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ"}
        except FileNotFoundError:
            return {"error": f"NekoCodeãƒã‚¤ãƒŠãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.nekocode_path}"}
        except Exception as e:
            return {"error": f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {str(e)}"}
    
    # ========================================
    # MCPãƒ—ãƒ­ãƒˆã‚³ãƒ«å®Ÿè£…
    # ========================================
    
    async def handle_initialize(self, params: Dict) -> Dict:
        """åˆæœŸåŒ–ãƒãƒ³ãƒ‰ãƒ©"""
        logger.info("MCP Server initializing...")
        return {
            "protocolVersion": "2024-11-05",
            "capabilities": {
                "tools": {"listChanged": False},
                "resources": {"subscribe": False, "listChanged": False}
            },
            "serverInfo": {
                "name": "nekocode",
                "version": "1.0.0"
            }
        }
    
    async def handle_tools_list(self, params: Dict) -> Dict:
        """ãƒ„ãƒ¼ãƒ«ä¸€è¦§ãƒãƒ³ãƒ‰ãƒ©"""
        return {"tools": self.tools}
    
    async def handle_resources_list(self, params: Dict) -> Dict:
        """ãƒªã‚½ãƒ¼ã‚¹ä¸€è¦§ãƒãƒ³ãƒ‰ãƒ©"""
        readme_path = os.path.join(os.path.dirname(__file__), "README.md")
        
        resources = []
        if os.path.exists(readme_path):
            resources.append({
                "uri": "nekocode://readme",
                "name": "NekoCode MCP Server README",
                "description": "ğŸ± NekoCodeã®ä½¿ã„æ–¹ã‚¬ã‚¤ãƒ‰ - ã‚»ãƒƒã‚·ãƒ§ãƒ³æ©Ÿèƒ½ã‚’æ´»ç”¨ã—ãŸé«˜é€Ÿè§£æ",
                "mimeType": "text/markdown"
            })
        
        return {"resources": resources}
    
    async def handle_resources_read(self, params: Dict) -> Dict:
        """ãƒªã‚½ãƒ¼ã‚¹èª­ã¿å–ã‚Šãƒãƒ³ãƒ‰ãƒ©"""
        uri = params.get("uri", "")
        
        if uri == "nekocode://readme":
            readme_path = os.path.join(os.path.dirname(__file__), "README.md")
            if os.path.exists(readme_path):
                with open(readme_path, "r", encoding="utf-8") as f:
                    contents = f.read()
                
                return {
                    "contents": [{
                        "uri": uri,
                        "mimeType": "text/markdown",
                        "text": contents
                    }]
                }
        
        return {"error": f"Resource not found: {uri}"}
    
    async def handle_tools_call(self, params: Dict) -> Dict:
        """ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œãƒãƒ³ãƒ‰ãƒ©"""
        tool_name = params.get("name")
        arguments = params.get("arguments", {})
        
        logger.info(f"Tool call: {tool_name} with args: {arguments}")
        
        try:
            if tool_name == "analyze":
                return await self._tool_analyze(arguments)
            elif tool_name == "session_create":
                return await self._tool_session_create(arguments)
            elif tool_name == "session_stats":
                return await self._tool_session_stats(arguments)
            elif tool_name == "session_update":
                return await self._tool_session_update(arguments)
            elif tool_name == "include_cycles":
                return await self._tool_include_cycles(arguments)
            elif tool_name == "include_graph":
                return await self._tool_include_graph(arguments)
            elif tool_name == "list_languages":
                return await self._tool_list_languages(arguments)
            elif tool_name == "replace_preview":
                return await self._tool_replace_preview(arguments)
            elif tool_name == "replace_confirm":
                return await self._tool_replace_confirm(arguments)
            elif tool_name == "insert_preview":
                return await self._tool_insert_preview(arguments)
            elif tool_name == "insert_confirm":
                return await self._tool_insert_confirm(arguments)
            elif tool_name == "movelines_preview":
                return await self._tool_movelines_preview(arguments)
            elif tool_name == "movelines_confirm":
                return await self._tool_movelines_confirm(arguments)
            elif tool_name == "edit_history":
                return await self._tool_edit_history(arguments)
            elif tool_name == "edit_show":
                return await self._tool_edit_show(arguments)
            elif tool_name == "ast_stats":
                return await self._tool_ast_stats(arguments)
            elif tool_name == "ast_query":
                return await self._tool_ast_query(arguments)
            elif tool_name == "scope_analysis":
                return await self._tool_scope_analysis(arguments)
            elif tool_name == "ast_dump":
                return await self._tool_ast_dump(arguments)
            elif tool_name == "moveclass_preview":
                return await self._tool_moveclass_preview(arguments)
            elif tool_name == "moveclass_confirm":
                return await self._tool_moveclass_confirm(arguments)
            elif tool_name == "memory_save":
                return await self._tool_memory_save(arguments)
            elif tool_name == "memory_load":
                return await self._tool_memory_load(arguments)
            elif tool_name == "memory_list":
                return await self._tool_memory_list(arguments)
            elif tool_name == "memory_timeline":
                return await self._tool_memory_timeline(arguments)
            elif tool_name == "config_show":
                return await self._tool_config_show(arguments)
            elif tool_name == "config_set":
                return await self._tool_config_set(arguments)
            elif tool_name == "watch_start":
                return await self._tool_watch_start(arguments)
            elif tool_name == "watch_status":
                return await self._tool_watch_status(arguments)
            elif tool_name == "watch_stop":
                return await self._tool_watch_stop(arguments)
            elif tool_name == "watch_stop_all":
                return await self._tool_watch_stop_all(arguments)
            elif tool_name == "watch_config":
                return await self._tool_watch_config(arguments)
            else:
                return {
                    "content": [{"type": "text", "text": f"Unknown tool: {tool_name}"}],
                    "isError": True
                }
        except Exception as e:
            logger.error(f"Tool execution error: {e}")
            return {
                "content": [{"type": "text", "text": f"ã‚¨ãƒ©ãƒ¼: {str(e)}"}],
                "isError": True
            }
    
    # ========================================
    # ãƒ„ãƒ¼ãƒ«å®Ÿè£…
    # ========================================
    
    async def _tool_analyze(self, args: Dict) -> Dict:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè§£æ"""
        path = args["path"]
        language = args.get("language", "auto")
        stats_only = args.get("stats_only", False)
        
        cmd_args = ["analyze", path]
        if language != "auto":
            cmd_args.extend(["--lang", language])
        
        # ğŸš€ NEW: Rustç‰ˆã«--stats-onlyã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ æ¸ˆã¿ï¼
        if stats_only:
            cmd_args.append("--stats-only")
        
        # Rustç‰ˆã§ã¯--io-threads â†’ --threads ã«å¤‰æ›´
        cmd_args.extend(["--threads", "8"])
        
        result = await self._run_nekocode(cmd_args)
        
        # stats_onlyã®å ´åˆã¯Rustå´ã§æ—¢ã«çµ±è¨ˆã‚µãƒãƒªãƒ¼å½¢å¼ã§å‡ºåŠ›ã•ã‚Œã‚‹ï¼ˆplaintextï¼‰
        if stats_only:
            if isinstance(result, dict) and "output" in result:
                # plain textãŒ{"output": "..."} å½¢å¼ã§è¿”ã•ã‚Œã‚‹å ´åˆ
                return {
                    "content": [{"type": "text", "text": result["output"]}]
                }
            elif isinstance(result, dict) and "raw" in result:
                # rawå‡ºåŠ›ã®å ´åˆ
                return {
                    "content": [{"type": "text", "text": result["output"]}]
                }
            else:
                # ãã®ä»–ã®å ´åˆã¯ãã®ã¾ã¾è¿”ã™
                return {
                    "content": [{"type": "text", "text": str(result)}]
                }
        
        # é€šå¸¸ã®JSONãƒ¢ãƒ¼ãƒ‰ã®å ´åˆ
        return {
            "content": [{"type": "text", "text": json.dumps(result, indent=2, ensure_ascii=False)}]
        }
    
    async def _tool_session_create(self, args: Dict) -> Dict:
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆ"""
        path = args["path"]
        result = await self._run_nekocode(["session-create", path])
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³IDæŠ½å‡ºï¼ˆJSONå½¢å¼ã¾ãŸã¯Rustç‰ˆã®ãƒ†ã‚­ã‚¹ãƒˆå‡ºåŠ›ï¼‰
        session_id = None
        if "session_id" in result:
            session_id = result["session_id"]
        elif "output" in result and isinstance(result["output"], str):
            # Rustç‰ˆã®å‡ºåŠ›: "Session created: XXXXX"
            import re
            match = re.search(r"Session created: ([a-f0-9]+)", result["output"])
            if match:
                session_id = match.group(1)
        
        if session_id:
            self.sessions[session_id] = {"path": path}
            logger.info(f"âœ… ã‚»ãƒƒã‚·ãƒ§ãƒ³ç™»éŒ²å®Œäº†: {session_id} -> {path}")
        else:
            logger.warning(f"âš ï¸ ã‚»ãƒƒã‚·ãƒ§ãƒ³IDæŠ½å‡ºå¤±æ•—: {result}")
        
        return {
            "content": [{"type": "text", "text": json.dumps(result, indent=2, ensure_ascii=False)}]
        }
    
    async def _tool_session_stats(self, args: Dict) -> Dict:
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ±è¨ˆ"""
        session_id = args["session_id"]
        
        if session_id not in self.sessions:
            return {
                "content": [{"type": "text", "text": f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ {session_id} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}],
                "isError": True
            }
        
        result = await self._run_nekocode(["session-command", session_id, "stats"])
        
        return {
            "content": [{"type": "text", "text": json.dumps(result, indent=2, ensure_ascii=False)}]
        }
    
    async def _tool_session_update(self, args: Dict) -> Dict:
        """âš¡ ã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ã‚¿ãƒ«è§£æ (è¶…é«˜é€Ÿæ›´æ–°)"""
        session_id = args["session_id"]
        verbose = args.get("verbose", False)
        dry_run = args.get("dry_run", False)
        
        if session_id not in self.sessions:
            return {
                "content": [{"type": "text", "text": f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ {session_id} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}],
                "isError": True
            }
        
        # ã‚³ãƒãƒ³ãƒ‰å¼•æ•°æ§‹ç¯‰
        cmd_args = ["session-update", session_id]
        if verbose:
            cmd_args.append("--verbose")
        if dry_run:
            cmd_args.append("--dry-run")
        
        result = await self._run_nekocode(cmd_args)
        
        # çµæœã®è§£æãƒ»ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        if verbose and isinstance(result, dict) and not result.get("error"):
            # verbose modeã®å ´åˆã€JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒæœŸå¾…ã•ã‚Œã‚‹
            content_text = json.dumps(result, indent=2, ensure_ascii=False)
        elif dry_run and isinstance(result, dict) and "output" in result:
            # dry-runã®å ´åˆã€ãƒ—ãƒ¬ãƒ¼ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå‡ºåŠ›
            content_text = result["output"]
        elif isinstance(result, dict) and "output" in result:
            # æ¨™æº–ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆ
            content_text = result["output"]
        else:
            # ãã®ä»–ã®å ´åˆã¯JSONã¨ã—ã¦ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
            content_text = json.dumps(result, indent=2, ensure_ascii=False)
        
        # æ€§èƒ½æƒ…å ±ã®æŠ½å‡ºãƒ»è¿½åŠ è¡¨ç¤º
        if isinstance(result, dict) and not dry_run and not result.get("error"):
            # æ€§èƒ½æ•°å€¤ã‚’æŠ½å‡ºã—ã¦ãƒã‚¤ãƒ©ã‚¤ãƒˆè¡¨ç¤º
            lines = content_text.split('\n')
            speedup_info = []
            
            for line in lines:
                if 'speedup' in line.lower() or 'faster' in line.lower():
                    speedup_info.append(line)
            
            if speedup_info:
                content_text += "\n\nğŸš€ **æ€§èƒ½ãƒã‚¤ãƒ©ã‚¤ãƒˆ:**\n" + "\n".join(f"  â€¢ {line}" for line in speedup_info)
        
        return {
            "content": [{"type": "text", "text": content_text}]
        }
    
    async def _tool_include_cycles(self, args: Dict) -> Dict:
        """å¾ªç’°ä¾å­˜æ¤œå‡º"""
        session_id = args["session_id"]
        
        if session_id not in self.sessions:
            return {
                "content": [{"type": "text", "text": f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ {session_id} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}],
                "isError": True
            }
        
        result = await self._run_nekocode(["session-command", session_id, "include-cycles"])
        
        return {
            "content": [{"type": "text", "text": json.dumps(result, indent=2, ensure_ascii=False)}]
        }
    
    async def _tool_include_graph(self, args: Dict) -> Dict:
        """ä¾å­˜é–¢ä¿‚ã‚°ãƒ©ãƒ•"""
        session_id = args["session_id"]
        
        if session_id not in self.sessions:
            return {
                "content": [{"type": "text", "text": f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ {session_id} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}],
                "isError": True
            }
        
        result = await self._run_nekocode(["session-command", session_id, "include-graph"])
        
        return {
            "content": [{"type": "text", "text": json.dumps(result, indent=2, ensure_ascii=False)}]
        }
    
    async def _tool_list_languages(self, args: Dict) -> Dict:
        """è¨€èªä¸€è¦§"""
        # æœ€æ–°ç‰ˆã§ã¯helpã‹ã‚‰è¨€èªæƒ…å ±ã‚’å–å¾—
        result = await self._run_nekocode(["--help"])
        
        if "output" in result:
            # LANGUAGESè¡Œã‚’æŠ½å‡º
            lines = result["output"].split('\n')
            lang_line = next((line for line in lines if 'LANGUAGES:' in line), "")
            languages = lang_line.replace('LANGUAGES:', '').strip() if lang_line else "JS/TS/C++/C/Python/C#"
            return {"content": [{"type": "text", "text": f"å¯¾å¿œè¨€èª: {languages}"}]}
        else:
            return {"content": [{"type": "text", "text": json.dumps(result, indent=2, ensure_ascii=False)}]}
    
    async def _tool_replace_preview(self, args: Dict) -> Dict:
        """ç½®æ›ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸è¦ï¼‰"""
        file_path = args["file_path"]
        pattern = args["pattern"]
        replacement = args["replacement"]
        
        # ç›´æ¥ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸è¦ï¼‰
        result = await self._run_nekocode(["replace-preview", file_path, pattern, replacement])
        
        return {
            "content": [{"type": "text", "text": json.dumps(result, indent=2, ensure_ascii=False)}]
        }
    
    async def _tool_replace_confirm(self, args: Dict) -> Dict:
        """ç½®æ›å®Ÿè¡Œï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸è¦ï¼‰"""
        preview_id = args["preview_id"]
        
        # ç›´æ¥ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸è¦ï¼‰
        result = await self._run_nekocode(["replace-confirm", preview_id])
        
        return {
            "content": [{"type": "text", "text": json.dumps(result, indent=2, ensure_ascii=False)}]
        }
    
    async def _tool_insert_preview(self, args: Dict) -> Dict:
        """æŒ¿å…¥ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸è¦ï¼‰"""
        file_path = args["file_path"]
        position = args["position"]
        content = args["content"]
        
        # ç›´æ¥ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸è¦ï¼‰
        result = await self._run_nekocode(["insert-preview", file_path, position, content])
        
        return {
            "content": [{"type": "text", "text": json.dumps(result, indent=2, ensure_ascii=False)}]
        }
    
    async def _tool_insert_confirm(self, args: Dict) -> Dict:
        """æŒ¿å…¥å®Ÿè¡Œï¼ˆç›´æ¥å®Ÿè¡Œï¼‰"""
        preview_id = args["preview_id"]
        
        # ç›´æ¥ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸è¦ï¼‰
        result = await self._run_nekocode(["insert-confirm", preview_id])
        
        return {
            "content": [{"type": "text", "text": json.dumps(result.get("output", result), indent=2, ensure_ascii=False)}]
        }
    
    async def _tool_movelines_preview(self, args: Dict) -> Dict:
        """è¡Œç§»å‹•ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸è¦ï¼‰"""
        srcfile = args["srcfile"]
        start_line = str(args["start_line"])
        line_count = str(args["line_count"])
        dstfile = args["dstfile"]
        insert_line = str(args["insert_line"])
        
        # ç›´æ¥ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸è¦ï¼‰
        result = await self._run_nekocode([
            "movelines-preview", srcfile, start_line, line_count, dstfile, insert_line
        ])
        
        return {
            "content": [{"type": "text", "text": json.dumps(result, indent=2, ensure_ascii=False)}]
        }
    
    async def _tool_movelines_confirm(self, args: Dict) -> Dict:
        """è¡Œç§»å‹•å®Ÿè¡Œï¼ˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼IDæŒ‡å®šï¼‰"""
        preview_id = args["preview_id"]
        
        # ç›´æ¥ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸è¦ï¼‰
        result = await self._run_nekocode(["movelines-confirm", preview_id])
        
        return {
            "content": [{"type": "text", "text": json.dumps(result, indent=2, ensure_ascii=False)}]
        }
    
    async def _tool_edit_history(self, args: Dict) -> Dict:
        """ç·¨é›†å±¥æ­´è¡¨ç¤ºï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸è¦ï¼‰"""
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸è¦ã§edit-historyãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ç›´æ¥èª­ã¿è¾¼ã¿
        try:
            import os
            import glob
            
            history_dir = "memory/edit_history"
            if not os.path.exists(history_dir):
                return {
                    "content": [{"type": "text", "text": json.dumps({"history": [], "total_count": 0, "summary": "ç·¨é›†å±¥æ­´ãªã—"}, indent=2, ensure_ascii=False)}]
                }
            
            # JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—ã—ã¦æœ€æ–°é †ã§ã‚½ãƒ¼ãƒˆ
            history_files = glob.glob(f"{history_dir}/*.json")
            history_files.sort(key=os.path.getmtime, reverse=True)
            
            history_list = []
            for file_path in history_files[:20]:  # æœ€æ–°20ä»¶
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        history_data = json.load(f)
                        history_list.append(history_data)
                except Exception as e:
                    logger.warning(f"Failed to load history file {file_path}: {e}")
            
            result = {
                "command": "edit-history",
                "total_count": len(history_files),
                "history": history_list,
                "summary": "æœ€æ–°20ä»¶ã®ç·¨é›†å±¥æ­´"
            }
            
        except Exception as e:
            logger.error(f"Edit history error: {e}")
            result = {"error": f"ç·¨é›†å±¥æ­´ã®å–å¾—ã«å¤±æ•—: {str(e)}"}
        
        return {
            "content": [{"type": "text", "text": json.dumps(result, indent=2, ensure_ascii=False)}]
        }
    
    async def _tool_edit_show(self, args: Dict) -> Dict:
        """ç·¨é›†è©³ç´°è¡¨ç¤º"""
        session_id = args["session_id"]
        edit_id = args["edit_id"]
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³å­˜åœ¨ãƒã‚§ãƒƒã‚¯
        if session_id not in self.sessions:
            return {
                "content": [{"type": "text", "text": f"Session not found: {session_id}"}],
                "isError": True
            }
        
        # ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œï¼ˆå¼•æ•°ã‚’å€‹åˆ¥ã«æ¸¡ã™ï¼‰
        result = await self._run_nekocode(["session-command", session_id, "edit-show", edit_id])
        
        return {
            "content": [{"type": "text", "text": json.dumps(result.get("output", result), indent=2, ensure_ascii=False)}]
        }
    
    # ========================================
    # MCPãƒ—ãƒ­ãƒˆã‚³ãƒ«é€šä¿¡
    # ========================================
    
    async def send_message(self, message: Dict):
        """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡ (stdout)"""
        json.dump(message, sys.stdout, ensure_ascii=False)
        sys.stdout.write('\n')
        sys.stdout.flush()
    
    async def receive_message(self) -> Optional[Dict]:
        """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å—ä¿¡ (stdin)"""
        try:
            line = sys.stdin.readline()
            if not line:
                return None
            return json.loads(line.strip())
        except json.JSONDecodeError as e:
            logger.error(f"JSON decode error: {e}")
            return None
        except Exception as e:
            logger.error(f"Message receive error: {e}")
            return None
    
    # ========================================
    # ğŸŒ³ ASTé–¢é€£ãƒ„ãƒ¼ãƒ«
    # ========================================
    
    async def _tool_ast_stats(self, args: Dict) -> Dict:
        """ASTçµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
        session_id = args["session_id"]
        result = await self._run_nekocode(["ast-stats", session_id])
        return {"content": [{"type": "text", "text": json.dumps(result, indent=2, ensure_ascii=False)}]}
    
    async def _tool_ast_query(self, args: Dict) -> Dict:
        """ASTæ§‹é€ ã‚’ã‚¯ã‚¨ãƒª"""
        session_id = args["session_id"]
        path = args["path"]
        result = await self._run_nekocode(["ast-query", session_id, path])
        return {"content": [{"type": "text", "text": json.dumps(result, indent=2, ensure_ascii=False)}]}
    
    async def _tool_scope_analysis(self, args: Dict) -> Dict:
        """ã‚¹ã‚³ãƒ¼ãƒ—è§£æã‚’å®Ÿè¡Œ"""
        session_id = args["session_id"]
        line = str(args["line"])
        result = await self._run_nekocode(["scope-analysis", session_id, line])
        return {"content": [{"type": "text", "text": json.dumps(result, indent=2, ensure_ascii=False)}]}
    
    async def _tool_ast_dump(self, args: Dict) -> Dict:
        """ASTæ§‹é€ ã‚’ãƒ€ãƒ³ãƒ—ï¼ˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«å¯¾å¿œãƒ»ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™ï¼‰"""
        session_id = args["session_id"]
        format_type = args.get("format", "tree")
        force = args.get("force", False)
        line_limit = args.get("limit")
        
        # ğŸ“‹ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™ã‚’å–å¾—
        token_config = self.config.get("token_limits", {})
        token_limit = token_config.get("ast_dump_max", 8000)
        summary_threshold = token_config.get("summary_threshold", 1000)
        allow_force = token_config.get("allow_force_output", True)
        
        # ğŸš¨ ã¾ãšast-statsã§ã‚µã‚¤ã‚ºç¢ºèª
        stats_result = await self._run_nekocode(["ast-stats", session_id])
        
        result = await self._run_nekocode(["ast-dump", session_id, format_type])
        
        # ğŸ”¥ ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™ãƒã‚§ãƒƒã‚¯
        if isinstance(result, dict):
            output_text = json.dumps(result, indent=2, ensure_ascii=False)
        else:
            output_text = str(result)
        
        # è¡Œæ•°åˆ¶é™é©ç”¨ï¼ˆæŒ‡å®šã•ã‚ŒãŸå ´åˆï¼‰
        if line_limit and not force:
            lines = output_text.split('\n')
            if len(lines) > line_limit:
                output_text = '\n'.join(lines[:line_limit])
                output_text += f"\n\n... ({len(lines) - line_limit} è¡Œçœç•¥) ..."
        
        # ãƒˆãƒ¼ã‚¯ãƒ³æ•°æ¨å®šï¼ˆæ–‡å­—æ•° / 4 = è¿‘ä¼¼ãƒˆãƒ¼ã‚¯ãƒ³æ•°ï¼‰
        estimated_tokens = len(output_text) // 4
        
        # force=True ã¾ãŸã¯ è¨­å®šã§å¼·åˆ¶è¨±å¯ã•ã‚Œã¦ã„ãªã„å ´åˆã¯åˆ¶é™ãƒã‚§ãƒƒã‚¯
        if not force and estimated_tokens > token_limit:
            # ğŸš¨ ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™è¶…é - è­¦å‘Šã¨ä»£æ›¿æ¡ˆæç¤º
            force_cmd = f'mcp__nekocode__ast_dump(session_id="{session_id}", format="{format_type}", force=True)'
            
            warning_msg = f"""ğŸš¨ **AST Dump ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™è¶…é** (è¨­å®š: {token_limit:,} tokens)

ğŸ“Š **å‡ºåŠ›ã‚µã‚¤ã‚ºåˆ†æ:**
â€¢ æ¨å®šãƒˆãƒ¼ã‚¯ãƒ³æ•°: **{estimated_tokens:,} tokens**
â€¢ è¨­å®šåˆ¶é™: {token_limit:,} tokens  
â€¢ è¶…éç‡: **{(estimated_tokens/token_limit):.1f}x**

âš ï¸ **è§£æã‚¢ãƒ—ãƒªã¨ã—ã¦ä½¿ã„ã‚„ã™ã•é‡è¦–ã§8000ã«è¨­å®šæ¸ˆã¿**

ğŸš€ **é¸æŠè‚¢:**
1. **ast_stats**: çµ±è¨ˆã‚µãƒãƒªãƒ¼ã®ã¿ï¼ˆæ¨å¥¨ï¼‰
2. **å¼·åˆ¶å‡ºåŠ›**: `{force_cmd}`
3. **è¡Œæ•°åˆ¶é™**: limit=50 ç­‰ã§éƒ¨åˆ†è¡¨ç¤º
4. **è¨­å®šå¤‰æ›´**: nekocode_config.json ã§åˆ¶é™å€¤èª¿æ•´

ğŸ“‹ **ASTçµ±è¨ˆã‚µãƒãƒªãƒ¼:**
{json.dumps(stats_result, indent=2, ensure_ascii=False) if isinstance(stats_result, dict) else str(stats_result)}

---
ğŸ’¡ **è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä¾‹** (nekocode_config.json):
```json
{{
    "token_limits": {{
        "ast_dump_max": 15000,
        "summary_threshold": 2000
    }}
}}
```"""
            
            return {"content": [{"type": "text", "text": warning_msg}]}
        
        # å¼·åˆ¶å‡ºåŠ›ã¾ãŸã¯åˆ¶é™å†…ã®å ´åˆ
        if force and not allow_force:
            return {"content": [{"type": "text", "text": "âŒ å¼·åˆ¶å‡ºåŠ›ã¯è¨­å®šã§ç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™"}]}
        
        # ã‚µã‚¤ã‚ºæƒ…å ±ã‚’ä»˜åŠ ï¼ˆsummary_thresholdè¶…éæ™‚ï¼‰
        if estimated_tokens > summary_threshold:
            size_info = f"ğŸ“Š å‡ºåŠ›ã‚µã‚¤ã‚º: {estimated_tokens:,} tokens\n\n"
            output_text = size_info + output_text
        
        return {"content": [{"type": "text", "text": output_text}]}
    
    # ========================================
    # ğŸ”„ ã‚¯ãƒ©ã‚¹ç§»å‹•ãƒ„ãƒ¼ãƒ«
    # ========================================
    
    async def _tool_moveclass_preview(self, args: Dict) -> Dict:
        """ã‚¯ãƒ©ã‚¹ç§»å‹•ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ç”Ÿæˆ"""
        session_id = args["session_id"]
        symbol_id = args["symbol_id"]
        target = args["target"]
        result = await self._run_nekocode(["moveclass-preview", session_id, symbol_id, target])
        return {"content": [{"type": "text", "text": json.dumps(result, indent=2, ensure_ascii=False)}]}
    
    async def _tool_moveclass_confirm(self, args: Dict) -> Dict:
        """ã‚¯ãƒ©ã‚¹ç§»å‹•ã‚’å®Ÿè¡Œ"""
        preview_id = args["preview_id"]
        result = await self._run_nekocode(["moveclass-confirm", preview_id])
        return {"content": [{"type": "text", "text": json.dumps(result, indent=2, ensure_ascii=False)}]}
    
    # ========================================
    # ğŸ’¾ ãƒ¡ãƒ¢ãƒªã‚·ã‚¹ãƒ†ãƒ ãƒ„ãƒ¼ãƒ«
    # ========================================
    
    async def _tool_memory_save(self, args: Dict) -> Dict:
        """ãƒ¡ãƒ¢ãƒªã«å†…å®¹ã‚’ä¿å­˜"""
        memory_type = args["memory_type"]
        name = args["name"]
        content = args["content"]
        result = await self._run_nekocode(["memory", "save", memory_type, name, content])
        return {"content": [{"type": "text", "text": json.dumps(result, indent=2, ensure_ascii=False)}]}
    
    async def _tool_memory_load(self, args: Dict) -> Dict:
        """ãƒ¡ãƒ¢ãƒªã‹ã‚‰å†…å®¹ã‚’èª­ã¿è¾¼ã¿"""
        memory_type = args["memory_type"]
        name = args["name"]
        result = await self._run_nekocode(["memory", "load", memory_type, name])
        return {"content": [{"type": "text", "text": json.dumps(result, indent=2, ensure_ascii=False)}]}
    
    async def _tool_memory_list(self, args: Dict) -> Dict:
        """ãƒ¡ãƒ¢ãƒªä¸€è¦§ã‚’å–å¾—"""
        cmd_args = ["memory", "list"]
        if "memory_type" in args:
            cmd_args.append(args["memory_type"])
        result = await self._run_nekocode(cmd_args)
        return {"content": [{"type": "text", "text": json.dumps(result, indent=2, ensure_ascii=False)}]}
    
    async def _tool_memory_timeline(self, args: Dict) -> Dict:
        """ãƒ¡ãƒ¢ãƒªã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã‚’å–å¾—"""
        cmd_args = ["memory", "timeline"]
        if "memory_type" in args:
            cmd_args.append(args["memory_type"])
        if "days" in args:
            cmd_args.extend(["--days", str(args["days"])])
        result = await self._run_nekocode(cmd_args)
        return {"content": [{"type": "text", "text": json.dumps(result, indent=2, ensure_ascii=False)}]}
    
    # ========================================
    # âš™ï¸ è¨­å®šãƒ„ãƒ¼ãƒ«
    # ========================================
    
    async def _tool_config_show(self, args: Dict) -> Dict:
        """ç¾åœ¨ã®è¨­å®šã‚’è¡¨ç¤º"""
        result = await self._run_nekocode(["config", "show"])
        return {"content": [{"type": "text", "text": json.dumps(result, indent=2, ensure_ascii=False)}]}
    
    async def _tool_config_set(self, args: Dict) -> Dict:
        """è¨­å®šã‚’å¤‰æ›´"""
        key = args["key"]
        value = args["value"]
        result = await self._run_nekocode(["config", "set", key, value])
        return {"content": [{"type": "text", "text": json.dumps(result, indent=2, ensure_ascii=False)}]}
    
    # ========================================
    # ğŸ” ãƒ•ã‚¡ã‚¤ãƒ«ç›£è¦–ãƒ„ãƒ¼ãƒ«
    # ========================================
    
    async def _tool_watch_start(self, args: Dict) -> Dict:
        """ãƒ•ã‚¡ã‚¤ãƒ«ç›£è¦–é–‹å§‹"""
        session_id = args["session_id"]
        result = await self._run_nekocode(["watch-start", session_id])
        return {"content": [{"type": "text", "text": json.dumps(result, indent=2, ensure_ascii=False)}]}
    
    async def _tool_watch_status(self, args: Dict) -> Dict:
        """ãƒ•ã‚¡ã‚¤ãƒ«ç›£è¦–çŠ¶æ…‹ç¢ºèª"""
        cmd_args = ["watch-status"]
        if "session_id" in args and args["session_id"]:
            cmd_args.append(args["session_id"])
        result = await self._run_nekocode(cmd_args)
        return {"content": [{"type": "text", "text": json.dumps(result, indent=2, ensure_ascii=False)}]}
    
    async def _tool_watch_stop(self, args: Dict) -> Dict:
        """ãƒ•ã‚¡ã‚¤ãƒ«ç›£è¦–åœæ­¢"""
        session_id = args["session_id"]
        result = await self._run_nekocode(["watch-stop", session_id])
        return {"content": [{"type": "text", "text": json.dumps(result, indent=2, ensure_ascii=False)}]}
    
    async def _tool_watch_stop_all(self, args: Dict) -> Dict:
        """å…¨ãƒ•ã‚¡ã‚¤ãƒ«ç›£è¦–åœæ­¢"""
        result = await self._run_nekocode(["watch-stop-all"])
        return {"content": [{"type": "text", "text": json.dumps(result, indent=2, ensure_ascii=False)}]}
    
    async def _tool_watch_config(self, args: Dict) -> Dict:
        """ãƒ•ã‚¡ã‚¤ãƒ«ç›£è¦–è¨­å®šè¡¨ç¤º"""
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã® file_watching ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç›´æ¥è¡¨ç¤º
        try:
            watch_config = self.config.get("file_watching", {})
            config_display = {
                "file_watching": watch_config,
                "èª¬æ˜": {
                    "debounce_ms": "ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´æ¤œçŸ¥ã®é…å»¶æ™‚é–“ï¼ˆãƒŸãƒªç§’ï¼‰",
                    "max_events_per_second": "1ç§’é–“ã®æœ€å¤§ã‚¤ãƒ™ãƒ³ãƒˆå‡¦ç†æ•°",
                    "exclude_patterns": "ç›£è¦–é™¤å¤–ãƒ‘ã‚¿ãƒ¼ãƒ³",
                    "include_extensions": "ç›£è¦–å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­",
                    "include_important_files": "æ‹¡å¼µå­ã«é–¢ä¿‚ãªãç›£è¦–ã™ã‚‹é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«"
                }
            }
            return {"content": [{"type": "text", "text": json.dumps(config_display, indent=2, ensure_ascii=False)}]}
        except Exception as e:
            return {"content": [{"type": "text", "text": f"è¨­å®šè¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {str(e)}"}], "isError": True}
    
    async def run(self):
        """MCPã‚µãƒ¼ãƒãƒ¼å®Ÿè¡Œ"""
        logger.info("ğŸ± NekoCode MCP Server starting...")
        logger.info(f"ğŸ“‚ NekoCode binary: {self.nekocode_path}")
        logger.info(f"ğŸ”§ Config: History {self.config['memory']['edit_history']['max_size_mb']}MB, "
                   f"Preview {self.config['memory']['edit_previews']['max_size_mb']}MB")
        token_config = self.config.get("token_limits", {})
        logger.info(f"ğŸ¯ Token Limits: AST Dump {token_config.get('ast_dump_max', 8000)}, "
                   f"Summary {token_config.get('summary_threshold', 1000)}")
        
        while True:
            try:
                # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å—ä¿¡
                message = await self.receive_message()
                if message is None:
                    break
                
                method = message.get("method")
                params = message.get("params", {})
                message_id = message.get("id")
                
                logger.info(f"Received: {method}")
                
                # ãƒãƒ³ãƒ‰ãƒ©å‘¼ã³å‡ºã—
                if method == "initialize":
                    result = await self.handle_initialize(params)
                elif method == "tools/list":
                    result = await self.handle_tools_list(params)
                elif method == "tools/call":
                    result = await self.handle_tools_call(params)
                elif method == "resources/list":
                    result = await self.handle_resources_list(params)
                elif method == "resources/read":
                    result = await self.handle_resources_read(params)
                else:
                    result = {"error": f"Unknown method: {method}"}
                
                # ãƒ¬ã‚¹ãƒãƒ³ã‚¹é€ä¿¡
                if message_id is not None:
                    response = {
                        "jsonrpc": "2.0",
                        "id": message_id,
                        "result": result
                    }
                    await self.send_message(response)
                
            except KeyboardInterrupt:
                break
            except Exception as e:
                logger.error(f"Main loop error: {e}")
                break
        
        logger.info("ğŸ± NekoCode MCP Server stopped")


if __name__ == "__main__":
    server = NekoCodeMCPServer()
    asyncio.run(server.run())